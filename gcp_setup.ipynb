{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup direnv & .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# MacOS\n",
    "brew install direnv\n",
    "\n",
    "# Ubuntu (Linux or Windows WSL2)\n",
    "sudo apt update\n",
    "sudo apt install -y direnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Create .env\n",
    "touch .env\n",
    "\n",
    "# Then add your environments variables in .env file\n",
    "'''\n",
    "# GCP Project\n",
    "GCP_PROJECT=<project_id_you_want>\n",
    "GCP_REGION=europe-west1\n",
    "\n",
    "# Cloud Storage\n",
    "BUCKET_NAME=nlp-shades-<your_github_name>\n",
    "\n",
    "# BigQuery\n",
    "BQ_REGION=EU\n",
    "BQ_DATASET=nlp_shades # must be letters (uppercase or lowercase), numbers, and underscores up to 1024 characters.\n",
    "DATA_SIZE=10k # 300k, 450k, all\n",
    "LOCAL_DATA_PATH=\"<path/to/the/package/model/dir>\"\n",
    "\n",
    "# Compute Engine\n",
    "INSTANCE=instance-nlp-shades-<your_github_name>\n",
    "\n",
    "# Docker\n",
    "GCR_IMAGE=nlp-shades-api\n",
    "'''\n",
    "\n",
    "# Create .envrc to load the environment variables\n",
    "touch .envrc\n",
    "echo dotenv  >> .envrcenv\n",
    "\n",
    "# Allow to load the .envrc\n",
    "direnv allow\n",
    "\n",
    "# ⚠️⚠️ If you update the .env file ⚠️⚠️\n",
    "direnv reload ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create GCP Service account"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Create a GCP account\n",
    "[here](https://github.com/lewagon/data-setup/blob/master/VM.md#google-cloud-platform-setup)\n",
    "\n",
    "2- Create a service account\n",
    "[here](https://github.com/lewagon/data-setup/blob/master/VM.md#google-cloud-cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Check your service account\n",
    "gcloud iam service-accounts list\n",
    "'''\n",
    "DISPLAY NAME                            EMAIL                                                              DISABLED\n",
    "Compute Engine default service account  161307270588-compute@developer.gserviceaccount.com                 False\n",
    "Compte de service (Wagon Bootcamp)      compte-de-service-wagon-bootca@PROJECT_ID.iam.gserviceaccount.com  False\n",
    "'''\n",
    "# ⚠️⚠️  If you are not on the right project ⚠️⚠️ \n",
    "gcloud config set project YOUR_PROJECT_ID\n",
    "\n",
    "# Then\n",
    "gcloud iam service-accounts list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cloud Storage (create a bucket  to save the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Create a bucket (from variables in .env)\n",
    "gsutil mb -l $GCP_REGION -p $GCP_PROJECT gs://$BUCKET_NAME\n",
    "\n",
    "# Then set gcloud on the correct GCP project ID\n",
    "gcloud config set project $GCP_PROJECT\n",
    "\n",
    "# And check \n",
    "gsutil ls\n",
    "'''--> gs://YOUR BUCKET NAME/'''\n",
    "\n",
    "# You can also check from the Google Cloud Console with the Cloud Storage module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Query (store the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataset where we’ll store & query preprocessed data !\n",
    "bq mk --project_id $GCP_PROJECT --data_location $BQ_REGION -d $BQ_DATASET\n",
    "\n",
    "# Then check par acquis de conscience\n",
    "bq show $BQ_DATASET\n",
    "\n",
    "# Finally create N new tables you want for train\n",
    "bq mk --location=$GCP_REGION $BQ_DATASET.raw_10k # small test\n",
    "bq mk --location=$GCP_REGION $BQ_DATASET.raw_300k  # 50% of the dataset\n",
    "bq mk --location=$GCP_REGION $BQ_DATASET.raw_450k  # 75% of the dataset\n",
    "bq mk --location=$GCP_REGION $BQ_DATASET.raw_all # all\n",
    "\n",
    "# Then :)\n",
    "bq show $BQ_DATASET.raw_10k\n",
    "bq show $BQ_DATASET.raw_300k\n",
    "bq show $BQ_DATASET.raw_450k\n",
    "bq show $BQ_DATASET.raw_all\n",
    "\n",
    "# You can also check from the Google Cloud Console with the BigQuerry module\n",
    "\n",
    "# 1- First load the data on Big Query (cf. data.py)\n",
    "make load_10k_data_to_bq\n",
    "make load_300k_data_to_bq\n",
    "make load_450k_data_to_bq\n",
    "make load_all_data_to_bq\n",
    "\n",
    "# 1bis- Go on Big Query to check the tables\n",
    "\n",
    "# 2- Run locally the model you want with the sample you want (cf. main.py) with either the csv file or by querying Big Query\n",
    "make run_ner_on_10k  # or\n",
    "make run_ner_on_300k # or\n",
    "make run_ner_on_450k # or\n",
    "make run_ner_on_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create The Virtual Machine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- GO \n",
    "[HERE](https://github.com/lewagon/data-setup/blob/master/VM.md#virtual-machine-vm)\n",
    "\n",
    "2- If you know exactly what type of VM you want to create, run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "INSTANCE=project-instance\n",
    "IMAGE_PROJECT=ubuntu-os-cloud\n",
    "IMAGE_FAMILY=ubuntu-2204-lts\n",
    "\n",
    "gcloud compute instances create $INSTANCE --image-project=$IMAGE_PROJECT --image-family=$IMAGE_FAMILY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup The Virtual Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Install zsh and omz \n",
    "sudo apt update\n",
    "sudo apt install -y zsh\n",
    "sh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n",
    "\n",
    "# Install pyenv and pyenv-virtualenv\n",
    "git clone https://github.com/pyenv/pyenv.git ~/.pyenv\n",
    "git clone https://github.com/pyenv/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv\n",
    "\n",
    "# Open ~/.zshrc in a Terminal code editor\n",
    "nano ~/.zshrc\n",
    "'''\n",
    "Add pyenv, ssh-agent and direnv to the list of zsh plugins on the line with plugins=(git) in ~/.zshrc: in the end, you should have plugins=(git pyenv ssh-agent direnv). Then, exit and save (Ctrl + X, Y, Enter).\n",
    "'''\n",
    "\n",
    "# Make sure that the modifications were indeed saved\n",
    "cat ~/.zshrc | grep \"plugins=\"\n",
    "\n",
    "# Add the pyenv initialization script to your ~/.zprofile\n",
    "cat << EOF >> ~/.zprofile\n",
    "export PYENV_ROOT=\"\\$HOME/.pyenv\"\n",
    "export PATH=\"\\$PYENV_ROOT/bin:\\$PATH\"\n",
    "eval \"\\$(pyenv init --path)\"\n",
    "EOF\n",
    "\n",
    "# Install Python\n",
    "sudo apt-get update; sudo apt-get install make build-essential libssl-dev zlib1g-dev \\\n",
    "libbz2-dev libreadline-dev libsqlite3-dev wget curl llvm \\\n",
    "libncursesw5-dev xz-utils tk-dev libxml2-dev libxmlsec1-dev libffi-dev liblzma-dev \\\n",
    "python3-dev\n",
    "\n",
    "# Now we need to start a new user session so that the updates in ~/.zshrc and ~/.zprofile are taken into account\n",
    "zsh --login\n",
    "\n",
    "# Install the same python version that you use for the project\n",
    "pyenv install 3.10.6\n",
    "pyenv global 3.10.6\n",
    "pyenv virtualenv 3.10.6 nlp-shades # ⚠️ don't forget to update it\n",
    "pyenv global nlp-shades # ⚠️ don't forget to update it\n",
    "\n",
    "# Github auth\n",
    "# ⚠️ Run this single command on YOUR machine, NOT in the VM ⚠️\n",
    "gcloud compute scp ~/.ssh/id_ed25519 $USER@$INSTANCE:~/.ssh/\n",
    "'''\n",
    "Check that $USER in your machine is the same that in your VM, it may be different ...\n",
    "If not, replace it with the $USER displayed on your VM !!\n",
    "\n",
    "gcloud compute scp ~/.ssh/id_ed25519 <user_from_VM>@$INSTANCE:~/.ssh/\n",
    "'''\n",
    "\n",
    "# ⚠️ Then, resume running commands in the VM ⚠️\n",
    "eval \"$(ssh-agent -s)\"\n",
    "ssh-add ~/.ssh/id_ed25519\n",
    "'''\n",
    "It should display:\n",
    "\n",
    "Agent pid 18827\n",
    "Identity added: /home/<user_from_VM>/.ssh/id_ed25519 (<your_email>)\n",
    "'''\n",
    "\n",
    "# Python code authentication to GCP\n",
    "'''\n",
    "The code of your package needs to be able to access your Big Query data warehouse.\n",
    "To do so, we will login to your account using the command below\n",
    "'''\n",
    "gcloud auth application-default login\n",
    "'''\n",
    "It should display a link to authenticate to GCP, copy/paste the link in your browser and authorize the acces. Then copy/paste the authorization code in the VM console.\n",
    "'''\n",
    "\n",
    "# Let’s verify that your Python code can now access your GCP resources. First, install some packages\n",
    "pip install -U pip\n",
    "pip install google-cloud-storage\n",
    "\n",
    "# Then, run Python code from the CLI. This should list your GCP buckets:\n",
    "python -c \"from google.cloud import storage; \\\n",
    "    buckets = storage.Client().list_buckets(); \\\n",
    "    [print(b.name) for b in buckets]\"\n",
    "\n",
    "# Let’s run a few tests inside your VM Terminal before we install it\n",
    "'''\n",
    "Default shell is /usr/bin/zsh\n",
    "'''\n",
    "echo $SHELL\n",
    "'''\n",
    "Python version is [version_installed]\n",
    "'''\n",
    "python --version\n",
    "'''\n",
    "Active GCP project is the same as $GCP_PROJECT in your .env file\n",
    "'''\n",
    "gcloud config list project\n",
    "\n",
    "\n",
    "# Your VM is now a data science beast 🔥 :) :)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train in the Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "First, you have to clone your package, install its requirements\n",
    "'''\n",
    "\n",
    "# You can copy your code to the VM by cloning your GitHub project\n",
    "git clone git@github.com:ekmillenium/nlp_shades_of_movie_reviews.git # ⚠️ don't forget to update it with the right project\n",
    "\n",
    "# Enter the directory\n",
    "cd <path/to/the/package/model/dir>\n",
    "\n",
    "# Create a .env file with all required parameters to use your package\n",
    "touch .env\n",
    "\n",
    "# Then updte the .env file with your parameters\n",
    "cat > .env \n",
    "'''# GCP Project'''\n",
    "GCP_PROJECT=<project_id_you_want>\n",
    "GCP_REGION=europe-west1\n",
    "'''# Cloud Storage'''\n",
    "BUCKET_NAME=nlp-shades-<your_github_name>\n",
    "'''# BigQuery'''\n",
    "BQ_REGION=EU\n",
    "BQ_DATASET=nlp_shades \n",
    "DATA_SIZE=10k\n",
    "LOCAL_DATA_PATH=\"<path/to/the/package/model/dir>\"\n",
    "'''# Compute Engine'''\n",
    "INSTANCE=instance-nlp-shades-<your_github_name>\n",
    "'''# Docker'''\n",
    "GCR_IMAGE=nlp-shades-api\n",
    "\n",
    "# Install direnv to load your .env\n",
    "sudo apt update\n",
    "sudo apt install -y direnv\n",
    "\n",
    "# Reconnect (simulate a user reboot) so that direnv works\n",
    "zsh --login\n",
    "\n",
    "# Allow your .envrc\n",
    "direnv allow .\n",
    "\n",
    "# Install the project package\n",
    "pip install .\n",
    "\n",
    "# Finally have fun !! :) :)\n",
    "make <the_command_you_want>\n",
    "\n",
    "## ⚠️⚠️ Switch OFF your VM to finish ⚠️⚠️ ##\n",
    "gcloud compute instances stop $INSTANCE\n",
    "gcloud compute instances list\n",
    "gcloud compute instances start $INSTANCE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Créer un service (alternative à Docker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "# Se connecter à la VM depuis la console (ou démarer la sessio via Gcloud)\n",
    "gcloud compute ssh\n",
    "\n",
    "# Etapes (créer un service sur un port custom à la manière de Dockerfile CMD)\n",
    "# --> SUR LA VM\n",
    "\n",
    "# 1- checker les ervices\n",
    "systemctl status system.slice\n",
    "# 2- installer service\n",
    "suod apt install uvicorn\n",
    "# 3- Créer le service dans /etc/systemd/system\n",
    "sudo touch nlp-shades-api.service\n",
    "# 4- Update le service\n",
    "sudo nano nlp-shades-api.service\n",
    "'''\n",
    "[Unit]\n",
    "Description=api for nlp-shades project\n",
    "After=network.target\n",
    "\n",
    "[Service]\n",
    "Type=simple\n",
    "User=a_dhuy\n",
    "ExecStart=sudo uvicorn nlp_shades.interface.api:app --reload\n",
    "Slice=nlp_shades.slice\n",
    "'''\n",
    "\n",
    "# 5- Reload tous les files de config\n",
    "sudo systemctl daemon-reload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_shades",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
